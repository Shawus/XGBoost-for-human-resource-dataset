{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8da5f1df",
   "metadata": {},
   "source": [
    "# 1. Data cleaning process for the model that predict whether a employee will leave"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f35ca3",
   "metadata": {},
   "source": [
    "## import package "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4763168",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff27f810",
   "metadata": {},
   "source": [
    "## import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71d72237",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"put your HR dataset.csv here\", encoding = 'unicode_escape', low_memory = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77349deb",
   "metadata": {},
   "source": [
    "## import exel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "587d6d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlrd\n",
    "import pandas\n",
    "features = pandas.read_excel(\"fexxxres.xlsx\") # Original xlsx file here is to help us drop the column at first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5bda609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROW_NUM\n",
      "['D', 'S', 'S', 'S', 'S', 'D', 'S', 'D', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'D', 'S', 'S', 'S', 'S', 'D', 'S', 'D', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'D', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'Y', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', nan, nan, nan, nan, nan, nan, nan, nan, 'S', nan, 'D', nan, 'S', 'S', 'S', 'S', 'S', 'S']\n"
     ]
    }
   ],
   "source": [
    "column_name_list = features['Column'].tolist()\n",
    "print(column_name_list[0])\n",
    "vals_list = features['ACTION'].tolist()\n",
    "print(vals_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0b5454c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop those feature that might not help for our modeling\n",
    "for index in range(253):\n",
    "    if (vals_list[index] != 'S'):\n",
    "        df.drop([column_name_list[index]],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3260582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode time-series data (if 13:00 return 13)\n",
    "def top_map_alt(time):\n",
    "    time = str(time)\n",
    "    t = [char for char in time]\n",
    "    if(len(t)<=3):\n",
    "        return 30\n",
    "    #return int(t[0] + t[1]) \n",
    "    \n",
    "    if t[0] == \"0\":\n",
    "        if t[1] == \"0\":\n",
    "            return 0\n",
    "        if t[1] == \"1\":\n",
    "            return 1\n",
    "        if t[1] == \"2\":\n",
    "            return 2\n",
    "        if t[1] == \"3\":\n",
    "            return 3\n",
    "        if t[1] == \"4\":\n",
    "            return 4\n",
    "        if t[1] == \"5\":\n",
    "            return 5\n",
    "        if t[1] == \"6\":\n",
    "            return 6\n",
    "        if t[1] == \"7\":\n",
    "            return 7\n",
    "        if t[1] == \"8\":\n",
    "            return 8\n",
    "        if t[1] == \"9\":\n",
    "            return 9\n",
    "    if t[0] == \"1\":\n",
    "        if t[1] == \"0\":\n",
    "            return 10\n",
    "        if t[1] == \"1\":\n",
    "            return 11\n",
    "        if t[1] == \"2\":\n",
    "            return 12\n",
    "        if t[1] == \"3\":\n",
    "            return 13\n",
    "        if t[1] == \"4\":\n",
    "            return 14\n",
    "        if t[1] == \"5\":\n",
    "            return 15   \n",
    "        if t[1] == \"6\":\n",
    "            return 16 \n",
    "        if t[1] == \"7\":\n",
    "            return 17\n",
    "        if t[1] == \"8\":\n",
    "            return 18\n",
    "        if t[1] == \"9\":\n",
    "            return 19\n",
    "    if t[0] == \"2\":\n",
    "        if t[1] == 0:\n",
    "            return 20\n",
    "        if t[1] == 1:\n",
    "            return 21\n",
    "        if t[1] == 2:\n",
    "            return 22\n",
    "        if t[1] == 3:\n",
    "            return 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7258c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data encoded from function top_map-alt() will form a new column\n",
    "# For example, (before we encode the data: EARLIEST_CLOCK_IN_TIME -> after we encode the data will create: new_EARLIEST_CLOCK_IN_TIME)\n",
    "def top_map_n(df, column):\n",
    "    df['new_'+ column] = 'ss'\n",
    "    df['new_'+ column] = df[column].apply(lambda x: top_map_alt(x))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bd9f9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process all time-series data\n",
    "top_map_n(df, 'XXXXXXXXXX_IN_TIME')\n",
    "top_map_n(df, 'XXXXXXXXXX_IN_TIME')\n",
    "top_map_n(df, 'XXXXXXXXXX_IN_TIME')\n",
    "top_map_n(df, 'XXXXXXXXXX_TIME')\n",
    "top_map_n(df, 'XXXXXXXXXX_TIME')\n",
    "top_map_n(df, 'XXXXXXXXXX_TIME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b230aee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second way to encode time-series data is like:\n",
    "# (if clock-in time is between 7:50~9:20, then we encode the data as 0. if colck-in time is between 9:21~18:30, the encode the data as 1)\n",
    "def free_milk(time):\n",
    "    time = str(time)\n",
    "    to_array = [char for char in time]\n",
    "    if(len(to_array)<=3):\n",
    "        return 4 \n",
    "    aa = to_array[0]+to_array[1]+to_array[3]+to_array[4]\n",
    "    \n",
    "    target = int(aa, base = 10)\n",
    "\n",
    "    if(target<749):\n",
    "        return 3\n",
    "    if(target<921):\n",
    "        return 0\n",
    "    if(target<1831):\n",
    "        return 1\n",
    "    return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9c7c36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def free_milk_super(df, column):\n",
    "    df[column] = df[column].apply(lambda x: free_milk(x))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82eda8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process all time-series data in second encoding way\n",
    "free_milk_super(df, 'XXXXXXXXXX_IN_TIME')\n",
    "free_milk_super(df, 'XXXXXXXXXX_IN_TIME')\n",
    "free_milk_super(df, 'XXXXXXXXXX_IN_TIME')\n",
    "free_milk_super(df, 'XXXXXXXXXX_TIME')\n",
    "free_milk_super(df, 'XXXXXXXXXX_TIME')\n",
    "free_milk_super(df, 'XXXXXXXXXX_TIME')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79249160",
   "metadata": {},
   "source": [
    "## Create a column records those person who clock-out quite precisely at regular clock-out time after working 8 hrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d448a5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_MASTER = []\n",
    "for i in range(len(df)):\n",
    "    TIME_MASTER.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c17fa8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Here is to encode the employee as 1/0 if the person meet our definition \n",
    "for i in range(len(df)):\n",
    "    if df[\"XXXXXXXXXX_HOUR\"].iloc[i] <= 8.08 and df[\"XXXXXXXXXX_HOUR\"].iloc[i] >= 8.0:\n",
    "        TIME_MASTER[i] = 1\n",
    "    else:\n",
    "        TIME_MASTER[i] = 0\n",
    "print(TIME_MASTER[28:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0b6d15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TIME_MASTER'] = TIME_MASTER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba8fe1d",
   "metadata": {},
   "source": [
    "## Remove those columns that might help model to predict the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb3d5d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop cheaters and deal with redundant features\n",
    "df.drop([\"XXXXXXXXXX_12M\"],axis=1, inplace=True)\n",
    "df.drop([\"XXXXXXXXXX_9M\"],axis=1, inplace=True)\n",
    "df.drop([\"XXXXXXXXXX_6M\"],axis=1, inplace=True)\n",
    "df.drop([\"XXXXXXXXXX_3M\"],axis=1, inplace=True)\n",
    "df.drop([\"XXXXXXXXXX_chr\"],axis=1, inplace=True)\n",
    "\n",
    "# df.drop([\"XXXXXXXXXX_ID\"], axis = 1, inplace=True)\n",
    "df.drop([\"XXXXXXXXXX_3M\"], axis = 1, inplace=True)\n",
    "df.drop([\"XXXXXXXXXX_6M\"], axis = 1, inplace=True)\n",
    "df.drop([\"XXXXXXXXXX_LAST\"], axis = 1, inplace=True)\n",
    "df.drop([\"XXXXXXXXXX_1st\"], axis = 1, inplace=True)\n",
    "df.drop([\"XXXXXXXXXX_HOUR\"], axis = 1, inplace=True)\n",
    "# df.drop([\"XXXXXXXXXX_EMP\"], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76108345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check columns with high proportion of missing value\n",
    "total = df.isnull().sum().sort_values(ascending = False)\n",
    "percent = round(df.isnull().sum().sort_values(ascending = False) / len(df) * 100, 2)\n",
    "percent[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2431477e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop those columns with high proportion of missing value\n",
    "df = df.drop(['XXXXXXXXXX_LOW'], axis = 1)\n",
    "df = df.drop(['XXXXXXXXXX_HIGH'], axis = 1)\n",
    "df = df.drop(['XXXXXXXXXX'], axis = 1)\n",
    "df = df.drop(['XXXXXXXXXX'], axis = 1)\n",
    "df = df.drop(['XXXXXXXXXX'], axis = 1)\n",
    "df = df.drop(['XXXXXXXXXX_HIGH'], axis = 1)\n",
    "\n",
    "# drop the columns that we don't need\n",
    "df = df.drop(['XXXXXXXXXX'], axis = 1)\n",
    "df = df.drop(['XXXXXXXXXX'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62092b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can decide whether to drop missing values by row, but be careful of the number of data and imbalance problem\n",
    "# df = df.dropna(axis = 1, how = 'any') ## axis == 1, drop column\n",
    "# df = df.dropna(axis = 0, how = 'any') ## axis == 0, drop row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a82806c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(862010, 164)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63e60bc",
   "metadata": {},
   "source": [
    "## Encode the data in datatype \"object\" and delete original column after create the new column for the data be encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d902ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map function (if you drop nan by row above, you can use this version of map function)\n",
    "# def top_map(df, column):\n",
    "    # new_list = df[column].tolist()\n",
    "    # de_list = list(set(new_list))\n",
    "    # new_dict = {}\n",
    "    # i = 0\n",
    "    # for label in de_list:\n",
    "        # new_dict.update({label:i})\n",
    "        # i = i + 1\n",
    "    # df['new_' + column] = df[column].map(new_dict)\n",
    "    # df = df.drop([column], axis = 1)\n",
    "    # return\n",
    "\n",
    "# ------------------------------------------------------\n",
    "\n",
    "# If the datatype of a column is object, then we need to encode using this version of map function.\n",
    "# The encoding process of this map function will skip nan, it won't encode the missing value. \n",
    "def top_map(df, column):\n",
    "    new_list = df[column].tolist()\n",
    "    de_list = list(set(new_list))\n",
    "    new_dict = {}\n",
    "    i = 0\n",
    "    for label in de_list:\n",
    "        x = pd.isnull(label)\n",
    "        if x == True:\n",
    "            continue\n",
    "        else:\n",
    "            new_dict.update({label:i})\n",
    "            i = i + 1\n",
    "    df['new_' + column] = df[column].map(new_dict)\n",
    "    df = df.drop([column], axis = 1)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ad69120",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_list = [\"XXXXXXXXXX_LAST\", \"XXXXXXXXXX_LAST\", \"XXXXXXXXXX_1st\", \"XXXXXXXXXX_chr\", \n",
    "           \"XXXXXXXXXX_ID\", \"XXXXXXXXXX_ID\", \"XXXXXXXXXX_LAST\", \"XXXXXXXXXX_1st\", \"XXXXXXXXXX_ID\", \"XXXXXXXXXX\", \"XXXXXXXXXX_LAST\"]\n",
    "\n",
    "my_type = 'object'\n",
    "dtypes = df.dtypes.to_dict()\n",
    "\n",
    "# encode the data in datatype \"object\" but skip the column if its name equals to the name in ID_list\n",
    "for col_name, typ in dtypes.items():\n",
    "    if (typ == my_type): #<--- type符合object的情況\n",
    "        if col_name in ID_list:\n",
    "            continue\n",
    "        else:\n",
    "            top_map(df, col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16063207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete original column after create the new column for the data be encoded\n",
    "my_type = 'object'\n",
    "dtypes = df.dtypes.to_dict()\n",
    "\n",
    "for col_name, typ in dtypes.items():\n",
    "    if (typ == my_type): #<---\n",
    "        if col_name in ID_list:\n",
    "            continue\n",
    "        else:\n",
    "            df = df.drop([col_name], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a3786125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "847994\n",
      "14016\n"
     ]
    }
   ],
   "source": [
    "# check the data distribution in target variable\n",
    "\n",
    "count_alive = 0\n",
    "count_unalive = 0\n",
    "\n",
    "for i in df[\"XXXXXXXXXX_LAST\"]:\n",
    "    # print(i)\n",
    "    if i == 1:\n",
    "        count_alive += 1\n",
    "    else:\n",
    "        count_unalive += 1\n",
    "        \n",
    "print(count_alive)\n",
    "print(count_unalive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e44d18",
   "metadata": {},
   "source": [
    "## Save the data which still contains NA after data-cleaning as a csv(Haven't deal with the imbalance problem in target variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4789a3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"XXXXXXXXXX.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "5863d9ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(862010, 223)"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a197c1",
   "metadata": {},
   "source": [
    "## Deal with the imbalance problem in target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a7f5f9ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39456, 223)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(df[df['XXXXXXXXXX_LAST'] == 1].sample(frac=.9).index)\n",
    "df = df.drop(df[df['XXXXXXXXXX_LAST'] == 1].sample(frac=.7).index)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "25aa4542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25440\n",
      "14016\n"
     ]
    }
   ],
   "source": [
    "# check the data distribution after we try to balance the data in target variable\n",
    "count_alive = 0\n",
    "count_unalive = 0\n",
    "\n",
    "for i in df[\"XXXXXXXXXX_LAST\"]:\n",
    "    # print(i)\n",
    "    if i == 1:\n",
    "        count_alive += 1\n",
    "    else:\n",
    "        count_unalive += 1\n",
    "        \n",
    "print(count_alive)\n",
    "print(count_unalive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4e3845cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data which is clean and balanced but still contains NA\n",
    "# df.to_csv(\"XXXXXXXXXX.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690fcd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- We finish our data-cleaning part for the model to predict whether a employee will leave --------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4f0b55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b8ead70",
   "metadata": {},
   "source": [
    "# 2. Data cleaning process for the model that predict whether a employee will get promoted or get promoted within six months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8f14c14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "775cc8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "promote_df = pd.read_csv(\"put your HR dataset.csv here\", encoding = 'unicode_escape', low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "4d2e8673",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlrd\n",
    "import pandas\n",
    "features = pandas.read_excel(\"fexxxres.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a1a6b139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROW_NUM\n",
      "['D', 'S', 'S', 'S', 'S', 'D', 'S', 'D', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'D', 'S', 'S', 'S', 'S', 'D', 'S', 'D', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'D', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'Y', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', nan, nan, nan, nan, nan, nan, nan, nan, 'S', nan, 'D', nan, 'S', 'S', 'S', 'S', 'S', 'S']\n"
     ]
    }
   ],
   "source": [
    "# same step as we done before\n",
    "column_name_list = features['Column'].tolist()\n",
    "print(column_name_list[0])\n",
    "vals_list = features['ACTION'].tolist()\n",
    "print(vals_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "3916af9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop those feature that might not help for our modeling\n",
    "for index in range(253):\n",
    "    if (vals_list[index] != 'S'):\n",
    "        promote_df.drop([column_name_list[index]],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ae3a38",
   "metadata": {},
   "source": [
    "## First type of encoding for time-series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "8343665c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_map_alt(time):\n",
    "    time = str(time)\n",
    "    t = [char for char in time]\n",
    "    if(len(t)<=3):\n",
    "        return 30\n",
    "    #return int(t[0] + t[1]) \n",
    "    \n",
    "    if t[0] == \"0\":\n",
    "        if t[1] == \"0\":\n",
    "            return 0\n",
    "        if t[1] == \"1\":\n",
    "            return 1\n",
    "        if t[1] == \"2\":\n",
    "            return 1\n",
    "        if t[1] == \"3\":\n",
    "            return 3\n",
    "        if t[1] == \"4\":\n",
    "            return 4\n",
    "        if t[1] == \"5\":\n",
    "            return 5\n",
    "        if t[1] == \"6\":\n",
    "            return 6\n",
    "        if t[1] == \"7\":\n",
    "            return 7\n",
    "        if t[1] == \"8\":\n",
    "            return 8\n",
    "        if t[1] == \"9\":\n",
    "            return 9\n",
    "    if t[0] == \"1\":\n",
    "        if t[1] == \"0\":\n",
    "            return 10\n",
    "        if t[1] == \"1\":\n",
    "            return 11\n",
    "        if t[1] == \"2\":\n",
    "            return 12\n",
    "        if t[1] == \"3\":\n",
    "            return 13\n",
    "        if t[1] == \"4\":\n",
    "            return 14\n",
    "        if t[1] == \"5\":\n",
    "            return 15   \n",
    "        if t[1] == \"6\":\n",
    "            return 16 \n",
    "        if t[1] == \"7\":\n",
    "            return 17\n",
    "        if t[1] == \"8\":\n",
    "            return 18\n",
    "        if t[1] == \"9\":\n",
    "            return 19\n",
    "    if t[0] == \"2\":\n",
    "        if t[1] == 0:\n",
    "            return 20\n",
    "        if t[1] == 1:\n",
    "            return 21\n",
    "        if t[1] == 2:\n",
    "            return 22\n",
    "        if t[1] == 3:\n",
    "            return 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a401e381",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_map_n(df, column):\n",
    "    df['new_'+ column] = 'ss'\n",
    "    df['new_'+ column] = df[column].apply(lambda x: top_map_alt(x))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "60b25fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_map_n(promote_df, 'XXXXXXXXXX_IN_TIME')\n",
    "top_map_n(promote_df, 'XXXXXXXXXX_IN_TIME')\n",
    "top_map_n(promote_df, 'XXXXXXXXXX_IN_TIME')\n",
    "top_map_n(promote_df, 'XXXXXXXXXX_TIME')\n",
    "top_map_n(promote_df, 'XXXXXXXXXX_TIME')\n",
    "top_map_n(promote_df, 'XXXXXXXXXX_TIME')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c00aa8f",
   "metadata": {},
   "source": [
    "## Second type of encoding for time-series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "fe967779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def free_milk(time):\n",
    "\n",
    "    time = str(time)\n",
    "    to_array = [char for char in time]\n",
    "    if(len(to_array)<=3):\n",
    "        return 4 \n",
    "    aa = to_array[0]+to_array[1]+to_array[3]+to_array[4]\n",
    "    \n",
    "    target = int(aa, base = 10)\n",
    "\n",
    "    if(target<749):\n",
    "        return 3\n",
    "    if(target<921):\n",
    "        return 0\n",
    "    if(target<1831):\n",
    "        return 1\n",
    "    return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "be413aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def free_milk_super(df, column):\n",
    "    df[column] = df[column].apply(lambda x: free_milk(x))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "046d7500",
   "metadata": {},
   "outputs": [],
   "source": [
    "free_milk_super(promote_df, 'XXXXXXXXXX_IN_TIME')\n",
    "free_milk_super(promote_df, 'XXXXXXXXXX_IN_TIME')\n",
    "free_milk_super(promote_df, 'XXXXXXXXXX_IN_TIME')\n",
    "free_milk_super(promote_df, 'XXXXXXXXXX_TIME')\n",
    "free_milk_super(promote_df, 'XXXXXXXXXX_TIME')\n",
    "free_milk_super(promote_df, 'XXXXXXXXXX_TIME')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a31f659",
   "metadata": {},
   "source": [
    "## Create a column records those person who clock-out quite precisely at regular clock-out time after working 8 hrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2167ce14",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_MASTER = []\n",
    "for i in range(len(promote_df)):\n",
    "    TIME_MASTER.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "4579f4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(promote_df)):\n",
    "    if promote_df[\"XXXXXXXXXX_HOUR\"].iloc[i] <= 8.08 and promote_df[\"XXXXXXXXXX_HOUR\"].iloc[i] >= 8.0:\n",
    "        TIME_MASTER[i] = 1\n",
    "    else:\n",
    "        TIME_MASTER[i] = 0\n",
    "print(TIME_MASTER[28:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "21fea6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "promote_df['TIME_MASTER'] = TIME_MASTER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9dd540",
   "metadata": {},
   "source": [
    "## Create a target variable which records whether a employee will get promoted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "de6e2459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "862010\n"
     ]
    }
   ],
   "source": [
    "IS_PROMOTED = [0]\n",
    "\n",
    "# Concept explanation: if the label in grade is changed from January to February, \n",
    "# then we record that employee as 1(get promoted) in column \"IS_Promoted\" in the row February \n",
    "grade_list = promote_df[\"XXXXXXXXXX\"].tolist()\n",
    "# i = 1\n",
    "for i in range(1, len(promote_df)):\n",
    "# for i in range(len(promote_df)):\n",
    "    if grade_list[i-1] != grade_list[i]:\n",
    "        IS_PROMOTED.append(1)\n",
    "    else:\n",
    "        IS_PROMOTED.append(0)\n",
    "\n",
    "print(len(IS_PROMOTED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d52046f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "promote_df[\"IS_PROMOTED\"] = IS_PROMOTED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7059c1",
   "metadata": {},
   "source": [
    "## Create a target variable which records whether a employee will get promoted in the next six months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "060992d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "862010\n"
     ]
    }
   ],
   "source": [
    "# Our name of target variable here is \"FUTURE_PROMOTED_6M\"\n",
    "FUTURE_PROMOTED_6M = []\n",
    "for i in range(len(promote_df)):\n",
    "    FUTURE_PROMOTED_6M.append(0)\n",
    "\n",
    "print(len(FUTURE_PROMOTED_6M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "36ba0b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we detect a row value as 1(get promoted) from \"IS_PROMOTED\", \n",
    "# then we need to fill the value in the past six rows with 1\n",
    "for i in range(5, len(promote_df)):\n",
    "    if IS_PROMOTED[i] == 1:\n",
    "        x = i\n",
    "        for j in range(6):\n",
    "            FUTURE_PROMOTED_6M[x-(j+1)] = 1\n",
    "            \n",
    "# print(FUTURE_PROMOTED_6M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "5d1cd493",
   "metadata": {},
   "outputs": [],
   "source": [
    "promote_df[\"FUTURE_PROMOTED_6M\"] = FUTURE_PROMOTED_6M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9514c5",
   "metadata": {},
   "source": [
    "## Remove those columns that might help model to predict the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "73e356b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop cheaters relate to promote and deal with redundant features\n",
    "promote_df.drop([\"XXXXXXXXXX_LAST\"],axis=1, inplace=True)\n",
    "promote_df.drop([\"XXXXXXXXXX_12M\"],axis=1, inplace=True)\n",
    "promote_df.drop([\"XXXXXXXXXX_9M\"],axis=1, inplace=True)\n",
    "promote_df.drop([\"XXXXXXXXXX_6M\"],axis=1, inplace=True)\n",
    "promote_df.drop([\"XXXXXXXXXX_3M\"],axis=1, inplace=True)\n",
    "promote_df.drop([\"XXXXXXXXXX_chr\"],axis=1, inplace=True)\n",
    "promote_df.drop([\"XXXXXXXXXX\"],axis=1, inplace=True)\n",
    "promote_df.drop([\"XXXXXXXXXX\"],axis=1, inplace=True)\n",
    "promote_df.drop([\"XXXXXXXXXX_GJL\"],axis=1, inplace=True)\n",
    "promote_df.drop([\"XXXXXXXXXX_MTH\"],axis=1, inplace=True)\n",
    "promote_df.drop([\"XXXXXXXXXX_6M\"],axis=1, inplace=True)\n",
    "promote_df.drop([\"XXXXXXXXXX_12M\"],axis=1, inplace=True)\n",
    "promote_df.drop([\"XXXXXXXXXX_18M\"],axis=1, inplace=True)\n",
    "promote_df.drop([\"XXXXXXXXXX_24M\"],axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# df.drop([\"EMPLOYEE_ID\"], axis = 1, inplace=True)\n",
    "promote_df.drop([\"XXXXXXXXXX_3M\"], axis = 1, inplace=True)\n",
    "promote_df.drop([\"XXXXXXXXXX_6M\"], axis = 1, inplace=True)\n",
    "promote_df.drop([\"XXXXXXXXXX_LAST\"], axis = 1, inplace=True)\n",
    "promote_df.drop([\"XXXXXXXXXX_1st\"], axis = 1, inplace=True)\n",
    "promote_df.drop([\"XXXXXXXXXX_HOUR\"], axis = 1, inplace=True)\n",
    "# promote_df.drop([\"NUM_TRAVEL_COUNT_EMP\"], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "2cb6c3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "promote_df = promote_df.drop(['XXXXXXXXXX_LOW'], axis = 1)\n",
    "promote_df = promote_df.drop(['XXXXXXXXXX_HIGH'], axis = 1)\n",
    "promote_df = promote_df.drop(['XXXXXXXXXX'], axis = 1)\n",
    "promote_df = promote_df.drop(['XXXXXXXXXX'], axis = 1)\n",
    "promote_df = promote_df.drop(['XXXXXXXXXX_LOW'], axis = 1)\n",
    "promote_df = promote_df.drop(['XXXXXXXXXX_HIGH'], axis = 1)\n",
    "promote_df = promote_df.drop(['XXXXXXXXXX'], axis = 1)\n",
    "promote_df = promote_df.drop(['XXXXXXXXXX'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "16426057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropna\n",
    "#df = df.dropna(axis = 1, how = 'any') ## axis == 1, drop column\n",
    "# promote_df = promote_df.dropna(axis = 0, how = 'any') ## axis == 0, drop row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48bd70d",
   "metadata": {},
   "source": [
    "## Encode the data in datatype \"object\" and delete original column after create the new column for the data be encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "3a30ee4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map function (This function won't encode the missing value)\n",
    "def top_map(df, column):\n",
    "    new_list = df[column].tolist()\n",
    "    de_list = list(set(new_list))\n",
    "    new_dict = {}\n",
    "    i = 0\n",
    "    for label in de_list:\n",
    "        x = pd.isnull(label)\n",
    "        if x == True:\n",
    "            continue\n",
    "        else:\n",
    "            new_dict.update({label:i})\n",
    "            i = i + 1\n",
    "    df['new_' + column] = df[column].map(new_dict)\n",
    "    df = df.drop([column], axis = 1)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "7aee04c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_list = [\"XXXXXXXXXX_LAST\", \"XXXXXXXXXX_LAST\", \"XXXXXXXXXX_1st\", \"XXXXXXXXXX_chr\", \n",
    "           \"XXXXXXXXXX_ID\", \"XXXXXXXXXX_ID\", \"XXXXXXXXXX_LAST\", \"XXXXXXXXXX_1st\", \"XXXXXXXXXX_ID\", \"XXXXXXXXXX\", \"XXXXXXXXXX_LAST\"]\n",
    "\n",
    "my_type = 'object'\n",
    "dtypes = promote_df.dtypes.to_dict()\n",
    "\n",
    "for col_name, typ in dtypes.items():\n",
    "    if (typ == my_type):\n",
    "        if col_name in ID_list:\n",
    "            continue\n",
    "        else:\n",
    "            top_map(promote_df, col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "28a639be",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_type = 'object'\n",
    "dtypes = promote_df.dtypes.to_dict()\n",
    "\n",
    "for col_name, typ in dtypes.items():\n",
    "    if (typ == my_type): \n",
    "        if col_name in ID_list:\n",
    "            continue\n",
    "        else:\n",
    "            promote_df = promote_df.drop([col_name], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "47883f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228835\n",
      "633175\n"
     ]
    }
   ],
   "source": [
    "# check the data distribution in target variable\n",
    "count_promote = 0\n",
    "count_unpromote = 0\n",
    "\n",
    "for i in promote_df[\"FUTURE_PROMOTED_6M\"]:\n",
    "    # print(i)\n",
    "    if i == 1:\n",
    "        count_promote += 1\n",
    "    else:\n",
    "        count_unpromote += 1\n",
    "        \n",
    "print(count_promote)\n",
    "print(count_unpromote)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a3dd62",
   "metadata": {},
   "source": [
    "## Save the data which still contains NA after data-cleaning as a csv(Haven't deal with the imbalance problem in target variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "d1e19ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "promote_df.to_csv(\"XXXXXXXXXX.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "ad3ec8bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(862010, 216)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promote_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be42a134",
   "metadata": {},
   "source": [
    "## Deal with the imbalance problem in target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "8f8f48c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(608740, 216)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promote_df = promote_df.drop(promote_df[promote_df['FUTURE_PROMOTED_6M'] != 1].sample(frac=.4).index)\n",
    "# promote_df = promote_df.drop(promote_df[promote_df['FUTURE_PROMOTED_6M'] == 1].sample(frac=.7).index)\n",
    "\n",
    "promote_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "eedae2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228835\n",
      "379905\n"
     ]
    }
   ],
   "source": [
    "# check the data distribution in target variable after we deal the imbalance problem\n",
    "count_promote = 0\n",
    "count_unpromote = 0\n",
    "\n",
    "for i in promote_df[\"FUTURE_PROMOTED_6M\"]:\n",
    "    # print(i)\n",
    "    if i == 1:\n",
    "        count_promote += 1\n",
    "    else:\n",
    "        count_unpromote += 1\n",
    "        \n",
    "print(count_promote)\n",
    "print(count_unpromote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "0e3b2754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataset which is clean and balanced but still contains NA, and you can begin to build your XGBoost model\n",
    "promote_df.to_csv(\"XXXXXXXXXX.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced53241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- We finish our data-cleaning part for the model to predict whether a employee will get promoted or promoted within six months -----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0dcf1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad63b709",
   "metadata": {},
   "source": [
    "# 3. Modeling part using XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fddeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d180d7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### load module\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import io\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca60c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "AutoML_df = pd.read_csv(\"the dataset correspond to the target you want to predict.csv\", encoding = 'unicode_escape', low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf4a04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data split part\n",
    "\n",
    "drop_column_list = ['XXXXXXXXXX_LAST', 'XXXXXXXXXX_ID', 'XXXXXXXXXX_LAST', 'XXXXXXXXXX_LAST', \n",
    "                    'XXXXXXXXXX_1st', 'XXXXXXXXXX_chr', 'XXXXXXXXXX_ID', 'XXXXXXXXXX', \n",
    "                    'XXXXXXXXXX_ID']\n",
    "# make sure that the dataset used to train the model doesn't contain the column in drop_column_list\n",
    "x = AutoML_df.drop(labels = drop_column_list, axis=1).values\n",
    "y = AutoML_df['XXXXXXXXXX_LAST'].values\n",
    "x_train , x_test , y_train , y_test = train_test_split(x, y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d59d81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "model = xgb.XGBClassifier(learning_rate = 0.05,\n",
    "                      n_estimators = 500,        # the number of tree you need - use 500 trees to build XGBoost\n",
    "                      max_depth = 5,             # the depth of the tree\n",
    "                      min_child_weight = 1,      # the weight of leave node               \n",
    "                      subsample = 1,             # Randomly choose 80% of dataset to build decision tree\n",
    "                      colsample_btree = 1,       # Randomly choose 80% of features to build decision tree\n",
    "                      colsample_bylevel = 1,\n",
    "                      random_state = 27,         # random state setting\n",
    "                      alpha = 0,\n",
    "                      reg_lambda = 1,\n",
    "                      max_leaves = 0,\n",
    "                      max_bin = 256\n",
    "                      )\n",
    "\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6886cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot feature importance\n",
    "\n",
    "model.get_booster().feature_names = AutoML_df.drop(labels = drop_column_list, axis=1).columns.values.tolist()\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(15,15))\n",
    "plot_importance(model.get_booster(),\n",
    "                height=0.5,\n",
    "                ax=ax,\n",
    "                max_num_features=64)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0da602e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction for test data\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdaf9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluate (accuracy rate)\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "print(\"accuarcy: %.2f%%\" % (accuracy*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0542e1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def confusio_matrix(y_test, y_predicted):\n",
    "    cm = confusion_matrix(y_test, y_predicted)\n",
    "    plt.figure(figsize=(15,10))\n",
    "    plt.clf()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Wistia)\n",
    "    classNames = ['0','1']\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    tick_marks = np.arange(len(classNames))\n",
    "    plt.xticks(tick_marks, classNames, rotation=45)\n",
    "    plt.yticks(tick_marks, classNames)\n",
    "    s = [['TN','FP'], ['FN', 'TP']]\n",
    "  \n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            plt.text(j,i, str(s[i][j])+\" = \"+str(cm[i][j]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebfe915",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusio_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82661f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some statistics to evaluate the model you build\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "def score(m, x_train, y_train, x_test, y_test, train=True):\n",
    "    if train:\n",
    "        pred=m.predict(x_train)\n",
    "        print('Train Result:\\n')\n",
    "        print(f\"Accuracy Score: {accuracy_score(y_train, pred)*100:.2f}%\")\n",
    "        print(f\"Precision Score: {precision_score(y_train, pred)*100:.2f}%\")\n",
    "        print(f\"Recall Score: {recall_score(y_train, pred)*100:.2f}%\")\n",
    "        print(f\"F1 score: {f1_score(y_train, pred)*100:.2f}%\")\n",
    "        # print(f\"Confusion Matrix:\\n {confusion_matrix(y_train, pred)}\")\n",
    "    elif train == False:\n",
    "        pred=m.predict(x_test)\n",
    "        print('Test Result:\\n')\n",
    "        print(f\"Accuracy Score: {accuracy_score(y_test, pred)*100:.2f}%\")\n",
    "        print(f\"Precision Score: {precision_score(y_test, pred)*100:.2f}%\")\n",
    "        print(f\"Recall Score: {recall_score(y_test, pred)*100:.2f}%\")\n",
    "        print(f\"F1 score: {f1_score(y_test, pred)*100:.2f}%\")\n",
    "        # print(f\"Confusion Matrix:\\n {confusion_matrix(y_test, pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0448dcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "score(model, x_train, y_train, x_test, y_test, train=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
